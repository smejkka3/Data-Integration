{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 1:  Schema Matching\n",
    "\n",
    "## Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = [('Imdb.Name', 'rt.Name'), ('Imdb.YearRange', 'rt.Year'), ('Imdb.ReleaseDate', 'rt.Release Date'), \n",
    "     ('Imdb.Director', 'rt.Director'), ('Imdb.Creator', 'rt.Creator'), ('Imdb.Cast', 'rt.Cast'),\n",
    "    ('Imdb.Duration', 'rt.Duration'), ('Imdb.RatingValue', 'rt.RatingValue'), ('Imdb.Genre', 'rt.Genre'), \n",
    "     ('Imdb.Description', 'rt.Description')]\n",
    "Num_of_all_correspondences = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "file_path1 = 'imdb.csv'\n",
    "file_path2 = 'rotten_tomatoes.csv'\n",
    "\n",
    "# Read the csv file using pandas read_csv method.\n",
    "data_frame1 = pd.read_csv(file_path1)\n",
    "data_frame2 = pd.read_csv(file_path2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 1: Label-Based Schema Matching\n",
    "Here, we want to find the correspondences between the columns from the two datasets with the help of only schema headers.\n",
    "\n",
    "1. Provide an algorithm. Specify the input, output, and time complexity.\n",
    "2. Implement the algorithm and report the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'Name', 'YearRange', 'ReleaseDate', 'Director', 'Creator', 'Cast', 'Duration', 'RatingValue', 'ContentRating', 'Genre', 'Url', 'Description']\n",
      "['Id', 'Name', 'Year', 'Release Date', 'Director', 'Creator', 'Actors', 'Cast', 'Language', 'Country', 'Duration', 'RatingValue', 'RatingCount', 'ReviewCount', 'Genre', 'Filming Locations', 'Description']\n",
      "[('Imdb.id', 'rt.id'), ('Imdb.name', 'rt.name'), ('Imdb.releasedate', 'rt.releasedate'), ('Imdb.director', 'rt.director'), ('Imdb.creator', 'rt.creator'), ('Imdb.cast', 'rt.cast'), ('Imdb.duration', 'rt.duration'), ('Imdb.ratingvalue', 'rt.ratingvalue'), ('Imdb.genre', 'rt.genre'), ('Imdb.description', 'rt.description')]\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import re\n",
    "\n",
    "schema_headers1 = list(data_frame1)\n",
    "schema_headers2 = list(data_frame2)\n",
    "lists = [schema_headers1, schema_headers2]\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "#reused code from https://stackoverflow.com/questions/3855537/fastest-way-to-sort-in-python\n",
    "def qsort(inlist):\n",
    "    if inlist == []: \n",
    "        return []\n",
    "    else:\n",
    "        pivot = inlist[0]\n",
    "        lesser = qsort([x for x in inlist[1:] if x < pivot])\n",
    "        greater = qsort([x for x in inlist[1:] if x >= pivot])\n",
    "        return lesser + [pivot] + greater\n",
    "\n",
    "def preprocessing(input_str):\n",
    "    input_str = input_str.strip().lower()\n",
    "    input_str = re.sub(\"\\W\", \"\", input_str).strip()\n",
    "    return input_str\n",
    "\n",
    "def distance(first_str, second_str):\n",
    "    first_str = preprocessing(first_str)\n",
    "    second_str = preprocessing(second_str)\n",
    "    leven = Levenshtein.ratio(first_str, second_str)\n",
    "    return leven\n",
    "\n",
    "for a, b in itertools.combinations(lists, 2):\n",
    "    result = []\n",
    "    for first in a:\n",
    "        for second in b:\n",
    "            ratio=distance(first,second)  \n",
    "            if ratio > 0.9:                  \n",
    "                result.append(('Imdb.'+first,'rt.'+second))  \n",
    "                break            \n",
    "print(result)  \n",
    "\n",
    "all_discovered_cor = len(result)\n",
    "discovered_cor_in_G = len(list(set(result).intersection(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.0\n",
      "recall:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", discovered_cor_in_G/all_discovered_cor)\n",
    "print(\"recall: \", discovered_cor_in_G/Num_of_all_correspondences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> &nbsp;&nbsp;&nbsp;&nbsp; Is there any parameter that affects the results?</p>\n",
    "<p> 3. What is the upsides and downsides of this method? When does it work and when\n",
    "not?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 2: Instance-Based Schema Matching\n",
    "Here, we want to find the correspondences between the columns from the two datasets with the help of only data values.\n",
    "1. Provide an algorithm. Specify the input, output, and time complexity.\n",
    "2. Implement the algorithm and report the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Imdb.Genre', 'rt.Genre'), ('Imdb.Director', 'rt.Director'), ('Imdb.Name', 'rt.Name'), ('Imdb.Creator', 'rt.Creator'), ('Imdb.Description', 'rt.Description')]\n",
      "run time: 45.929708000000005 s\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "r = random.randint(0,len(data_frame1))\n",
    "if(len(data_frame1) > len(data_frame2)):\n",
    "    samples = int(math.ceil(len(data_frame1)/100))\n",
    "    values1 = data_frame1._slice(slice(r-samples, r)).values\n",
    "    values2 = data_frame2.values\n",
    "    headers1= list(data_frame1)\n",
    "    headers2= list(data_frame2)\n",
    "else:\n",
    "    samples = int(math.ceil(len(data_frame2)/100))\n",
    "    values2 = data_frame2._slice(slice(r-samples, r)).values\n",
    "    values1 = data_frame1.values\n",
    "    \n",
    "    headers1= list(data_frame1)\n",
    "    headers2= list(data_frame2)\n",
    "\n",
    "lists = [values1, values2]\n",
    "    \n",
    "t_a = time.clock()\n",
    "\n",
    "for a, b in itertools.combinations(lists, 2):\n",
    "    merged = []\n",
    "    for first in itertools.chain.from_iterable(a):\n",
    "        for second in itertools.chain.from_iterable(b):\n",
    "            if(isinstance(first,str) and isinstance(second,str)):\n",
    "                if(abs(len(first)-len(second)) < 1):\n",
    "                    if distance(first, second) > 0.9:\n",
    "                        i_a,j_a = np.where(a==first)\n",
    "                        column_name1 = headers1[j_a[0]]\n",
    "                        del headers1[j_a[0]]\n",
    "                        i_b,j_b = np.where(b==second)\n",
    "                        column_name2 = headers2[j_b[0]]\n",
    "                        del headers2[j_b[0]]\n",
    "                        match = ('Imdb.'+column_name2,'rt.'+column_name1)\n",
    "                        merged.append(match)\n",
    "                        a = np.delete(a, j_a, 1)\n",
    "                        b = np.delete(b, j_b, 1)\n",
    "                        break\n",
    "            elif(isinstance(first, (int, float)) and isinstance(second, (int, float))):\n",
    "                if pd.isnull(first):\n",
    "                    break\n",
    "                elif pd.isnull(second):\n",
    "                    break\n",
    "                else:\n",
    "                    if abs(first-second) < 1:\n",
    "                        i_a,j_a = np.where(a==first)\n",
    "                        column_name1 = headers1[j_a[0]]\n",
    "                        del headers1[j_a[0]]\n",
    "                        i_b,j_b = np.where(b==second)\n",
    "                        column_name2 = headers2[j_b[0]]\n",
    "                        del headers2[j_b[0]]\n",
    "                        match = ('Imdb.'+column_name2,'rt.'+column_name1)\n",
    "                        merged.append(match)\n",
    "                        a = np.delete(a, j_a, 1)\n",
    "                        b = np.delete(b, j_b, 1)\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "print(merged)\n",
    "t_b = time.clock()\n",
    "total_time = t_b-t_a\n",
    "print(\"run time:\", total_time,\"s\")\n",
    "\n",
    "all_discovered_cor = len(merged)\n",
    "discovered_cor_in_G = len(list(set(merged).intersection(G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> &nbsp;&nbsp;&nbsp;&nbsp; Is there any parameter that affects the results?</p>\n",
    "<p> 3. What is the upsides and downsides of this method? When does it work and when\n",
    "not?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  1.0\n",
      "recall:  0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", discovered_cor_in_G/all_discovered_cor)\n",
    "print(\"recall: \", discovered_cor_in_G/Num_of_all_correspondences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
